{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOr9Ualnr/fLkQxHjmudNGL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Write a program to demonstrate POS tagging: Hidden markov model."],"metadata":{"id":"ZeQR1EdI80IP"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"SxP2TZzR8lt_","executionInfo":{"status":"ok","timestamp":1715340589359,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sree Datta","userId":"14318501174238634358"}}},"outputs":[],"source":["# importing numpy for matrix operations.\n","import numpy as np\n","\n","# The provided code defines a class called HMM_POS_Tagging that implements a Hidden Markov Model (HMM) for Part-of-Speech (POS) tagging.\n","class HMM_POS_Tagging:\n","\n","    def __init__(self, states, observations, transition_prob, emission_prob, initial_prob): # constructor method for the class.\n","\n","        self.states = states # A list of possible hidden states in the HMM.\n","        self.observations = observations # A list of possible observations that can be emitted by the HMM\n","        self.transition_prob = transition_prob # A 2D array representing the transition probabilities between states.\n","        self.emission_prob = emission_prob # A 2D array representing the emission probabilities for each state\n","        self.initial_prob = initial_prob # A 1D array representing the initial state probabilities.\n","\n","    def viterbi(self, obs_sequence):\n","        T = len(obs_sequence) # Calculates the length of the observation sequence.\n","        N = len(self.states) # Calculates the number of possible hidden states.\n","        viterbi=np.zeros((N,T))\n","\n","        #  Initializes a 2D NumPy array called viterbi with dimensions equal to the number of states and the length of the observation sequence\n","        backpointers = np.zeros((N, T), dtype=int)\n","        # Initializes a 2D NumPy array called backpointers with dimensions equal to the number of states and the length of the observation sequence\n","\n","        for i in range(N):\n","            viterbi[i][0] = self.initial_prob[i] * self.emission_prob[i][self.observations.index(obs_sequence[0])]\n","            # This line calculates the initial Viterbi probability for each state. It multiplies the initial probability of the state (self.initial_prob[i]) with the emission probability of the first observation (obs_sequence[0]) given that state (self.emission_prob[i]\n","\n","            backpointers[i][0] = 0 # This line initializes the backpointer for the first time step as 0 for all states\n","            for t in range(1, T): # (index 1). This loop calculates the Viterbi probabilities for the remaining time steps.\n","              for s in range(N):\n","\n","                viterbi[s][t] = max(viterbi[prev_s][t - 1] * self.transition_prob[prev_s][s] *\n","                                    self.emission_prob[s][self.observations.index(obs_sequence[t])]\n","                                    for prev_s in range(N))\n","\n","                \"\"\" viterbi[s][t]: This is the probability of the most likely sequence of hidden states up to time t, ending in state s.\n","                max(...): This is a loop that iterates over all possible previous states prev_s at time t-1.\n","\n","                viterbi[prev_s][t - 1]: This is the probability of the most likely sequence of hidden states up to time t-1, ending in state prev_s.\n","\n","                self.transition_prob[prev_s][s]: This is the probability of transitioning from state prev_s to state s.\n","\n","                self.emission_prob[s][self.observations.index(obs_sequence[t])]: This is the probability of observing obs_sequence[t] given that the current state is s.\n","\n","                obs_sequence[t]: This is the observation at time t.\n","\n","                \"\"\"\n","\n","                backpointers[s][t] = np.argmax([viterbi[prev_s][t - 1] * self.transition_prob[prev_s][s]\n","                                                 for prev_s in range(N)])\n","                # viterbi[prev_s][t - 1]: This represents the probability of being in state prev_s at time t - 1.\n","                # self.transition_prob[prev_s][s]: This represents the transition probability from state prev_s to state s.\n","                # The np.argmax function is used to find the index of the maximum value in the list [viterbi[prev_s][t - 1] * self.transition_prob[prev_s][s]]\n","\n","                best_path_prob = max(viterbi[s][T - 1] for s in range(N))\n","\n","                \"\"\" viterbi[s][T - 1]: This represents the probability of being in state s at the final time step, T - 1.\n","                    for s in range(N): This iterates through all possible states, s, at time T - 1.\n","                    max: This function returns the maximum value in the list [viterbi[s][T - 1] for s in range(N)].\n","                \"\"\"\n","\n","        best_path_pointer = np.argmax([viterbi[s][T - 1] for s in range(N)])\n","        best_path = [self.states[best_path_pointer]]\n","\n","        \"\"\"np.argmax([viterbi[s][T - 1] for s in range(N)]): This line finds the index of the most likely state at the final time step, T - 1.\n","            best_path_pointer: This variable stores the index of the most likely final state.\n","              best_path = [self.states[best_path_pointer]]: This line initializes the list of most likely states with the most likely final state.\n","        \"\"\"\n","        for t in range(T - 1, 0, -1):\n","            best_path_pointer = backpointers[best_path_pointer][t]\n","            best_path.insert(0, self.states[best_path_pointer])\n","\n","            \"\"\" for t in range(T - 1, 0, -1): This loop iterates backwards through time, starting from the final time step T - 1 and ending at time step 1.\n","              best_path_pointer = backpointers[best_path_pointer][t]: This line uses the backpointers matrix to find the most likely previous state at time t given the current most likely state, best_path_pointer.\n","                best_path.insert(0, self.states[best_path_pointer]): This line adds the most likely state at time t to the beginning of the best_path list.\n","            \"\"\"\n","\n","        return best_path, best_path_prob"]},{"cell_type":"markdown","source":["# Program"],"metadata":{"id":"XtSas8ToRHdE"}},{"cell_type":"code","source":["states = ['Noun', 'Verb', 'Adjective']\n","observations = ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n","transition_prob = np.array([[0.3, 0.3, 0.4],\n","                             [0.1, 0.6, 0.3],\n","                             [0.2, 0.4, 0.4]])\n","emission_prob = np.array([[0.1, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n","                           [0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1],\n","                           [0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1]])\n","initial_prob = np.array([0.3, 0.3, 0.4])\n","\n","hmm = HMM_POS_Tagging(states, observations, transition_prob, emission_prob, initial_prob)\n","obs_sequence = ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n","best_path, best_path_prob = hmm.viterbi(obs_sequence)\n","\n","print(\"Best Path (POS Tags):\", best_path)\n","print(\"Probability of Best Path:\", best_path_prob)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zbdl2Mg98rUZ","executionInfo":{"status":"ok","timestamp":1715318480259,"user_tz":-330,"elapsed":1018,"user":{"displayName":"Sree Datta","userId":"14318501174238634358"}},"outputId":"4f6b72d9-357b-4dec-f59f-b234e3a530f5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Path (POS Tags): ['Adjective', 'Verb', 'Verb', 'Verb', 'Verb', 'Verb', 'Verb', 'Verb', 'Verb']\n","Probability of Best Path: 1.791590400000001e-11\n"]}]}]}